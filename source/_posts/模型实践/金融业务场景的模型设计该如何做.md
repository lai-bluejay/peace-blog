---
title: 金融业务场景的模型设计该如何做
date: '2019-03-09 12:25:22'
updated: '2019-03-09 12:26:09'
tags:
  - 模型设计
  - 互联网金融建模
  - 样本定义
categories:
  - 模型实践
abbrlink: fb5893d1
---
# 模型设计



## 问题定义

### 什么是我们的目标用户。

主要关系到什么是应该进入模型的样本。金融领域有这样一个说法，Through the door，TTD，即业务入口是一个门，有被拒之门外的（拒绝），也有进入门里的（通过）。通过的用户可以知道好坏。但是拒绝的用户其实是未知的，虽然很多用户因为可能逾期被拒绝。

如果一直在已知数据上训练模型，就会缺失一部分数据的信息。也就是如何feed这个模型，虽然专家模型的引入可以解决一部分的问题，可能引入更多/更少的坏未知样本。如果拒绝本来也是一种信息，如何加入拒绝样本的影响需要探索一下。

### 建模的目标

其实和目标用户类似，这两个问题合起来就是“要对哪部分用户做什么事情”。

例如，如果我们做申请信用评分卡（即A卡），显而易见，建模的目标是申请客户在当前业务下可能的逾期率。通常我们会听到，客户逾期通常分为还款意愿和还款能力，但实际上可以做一些简单的转换：

1. 把还款意愿不足的用户定义为反欺诈的任务
2. A卡评估还款能力，通常还款能力低的还款意愿也低。

这边需要注意的几个问题有：

1. 单纯的欺诈用户，如何在早期就发现？通常需要case的积累和domain knowledge，包括常见黑产的积累。
2. reject inference。



### 其他

还包括了其他一些会影响样本和label的定义：

- 观察期和表现期的定义

- 好坏样本的定义。比如申请评分卡，如何定义好样本呢？建议是根据逾期用户的滚动率（即逾期用户好久继续逾期的概率），确定“较短逾期+较低滚动率”。假设我们滚动率如下，那可能会选择3天做为坏样本的阈值。

    ![image-20190525201521867](../../uploads/assets/image-20190525201518518.png)

- 模型的预设拒绝率（由业务场景决定，相当于做一步初筛，模型做好初筛后的业务平衡。业务量 VS 风险）



### 各个场景下的建模概述

- 获客阶段：用户响应模型，风险预筛选模型，流失预警模型
- 授信阶段：申请评分模型，反欺诈模型，风险定价模型，收益评分模型。
- 贷后阶段：行为评分模型，交易欺诈模型，客户流失模型。
- 催收阶段：催收评分模型，催收敏感度模型，失联率模型，滚动率模型

  

## 模型设计

### 模型样本的选择

同样是针对用户的选择，根据建模目标的不同，会有不同的样本进入模型，即使是相同的特征，在不同样本分布上，所带有的信息量也不相同。

常见的一定不进模型的样本：

1. baseline所拒绝的（包括一些强的规则和红线，但对于某些阈值的规则，可能需要考虑是否做拒绝推断）

2. 明确是欺诈用户的

    

常见的需要筛选用户样本的模型：

1. 催收敏感度模型：需要将没有催收表现的去除
2. 某些特定场景才出现的用户
    - 尤其是存在线下或者某些概念上的“商铺”，如果是商铺级的欺诈；或者服务纠纷/商户跑路等造成的逾期



### 数据获取

需要注意的点：

1. 在确定样本之后，数据的选择范围只能是确定样本内的数据。例如要做表现期的模型，仍处于观察期的用户样本可能就会影响数据分布。
2. 一定要注意使用稳定的数据：稳定包括服务稳定性和数据上游稳定性



### 数据验证

1. 缺失率的验证：看历史上能获得的数据中，数据的完整性是怎么样的。
2. 稳定性验证：主要考察时间序列上，数据特征的分布是否稳定（PSI），均值方差等统计指标





### 特征预处理

#### 特征预筛选：

1. 移除特征：缺失率过高（阈值50%）
2. 移除与
3. 特征变换：
    - 变为正态分布后$\mu + 3\sigma$的原则，高于这部分的异常值可以做截断；（尤其对于异常值敏感的模型）
    - 采取log变换(减少最大值影响)
    - 如果是排序数据，可以做排序衰减（i/log i)
4. 归一化后：方差很小或为0（即数据无明显差异）；考虑去除n%都相同的特征。
5. 

#### 特征处理

1. 数值特征离散化：可以使用等频分桶/等宽分桶/基于树模型进行分桶。分桶后可以使用woe值或者桶编号代替。（woe的好处？）
2. 特征筛选：
    - IV筛选
    - Lasso
3. 特征交叉
4. 进行一些特征的非线性变换



### 模型训练

在定义好样本和特征之后，就可以对特征集进行模型训练。

常见的模型训练方法有：

1. LR
2. xgboost/lightgbm
3. ensemble

#### 模型评估

  常见的评估指标有：

1. AUC

2. KS

3. 人群分布PSI

    

#### 在数据量足够的时候为什么要训练集，验证集，测试集

1. 训练集用来估计模型（即生成一个模型，estimator），验证集用来选择模型（根据训练集使用的算法和参数不同，确定最优的模型），测试集用来测试模型的泛化能力。
2. Error = Bias + Variance。

> Error反映的是整个模型的准确度，Bias反映的是模型在样本上的输出与真实值之间的误差，即模型本身的精准度，Variance反映的是模型每一次输出结果与模型输出期望之间的误差，即模型的稳定性。
>
> 验证集的bias必定是比实际值要低的，因为验证集和训练集之间更加相似（时间关系），而且是用验证集来对模型进行选择的。因此测试集有必要，抽象出一个假设不知道label的测试集，降低variance，来评估模型。
>
> low bias 可能会导致过拟合（验证集效果好），使用cv可以降低。

3. 可以尝试 8:1:1切分数据，训练集内cv，验证集验证，测试集测试结果。



## 模型布署

常见有几种模型布署方式：

1. 直接布署模型文件（python joblib等）
2. 转换乘PMML文件（较慢且较大，不适用于大模型布署
3. 将模型直接转换为数值型代码（github.com/m2cgen等）



到这边为止，一个可上线的模型初版，已经就有了。为什么说是初版呢？因为我们还有几件事没有做：

1. 如果是申请评分卡/模型，是否需要做拒绝推断（Reject Inference）
2. 如何保证模型的稳定性
3. 如何提供模型的可解释性。

## 模型需要做什么。

1. 上线前做好特征验证和特征工程，离线训练表现好的模型，同时做好模型设计的评估和review。

2. 上线后做好线上数据的监控，包括特征和用户群的稳定性，如PSI等指标。